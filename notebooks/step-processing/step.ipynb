{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "413be720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "ae95ef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weather data...\n",
      "Loading typhoon impact data...\n",
      "Loading typhoon duration/dates data...\n",
      "Weather data shape: (1828, 90)\n",
      "Impact data shape: (1776, 26)\n",
      "Duration data shape: (84, 7)\n",
      "\n",
      "Datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "print(\"Loading weather data...\")\n",
    "weather_data = pd.read_csv('../../data/Daily Data.csv')\n",
    "\n",
    "print(\"Loading typhoon impact data...\")\n",
    "impact_data = pd.read_csv('../../data/data_withno_weatherdata.csv')\n",
    "\n",
    "print(\"Loading typhoon duration/dates data...\")\n",
    "duration_data = pd.read_csv('../../data/Duration of typhoon.csv')\n",
    "\n",
    "print(f\"Weather data shape: {weather_data.shape}\")\n",
    "print(f\"Impact data shape: {impact_data.shape}\")\n",
    "print(f\"Duration data shape: {duration_data.shape}\")\n",
    "print(\"\\nDatasets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d33923",
   "metadata": {},
   "source": [
    "## Reset column for impact_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "6dd55952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Typhoon Name', 'Year', 'Region', 'Province', 'City/Municipality',\n",
       "       'Families', 'Person', 'Brgy', 'Dead', 'Injured/Ill', 'Missing',\n",
       "       'Totally', 'Partially', 'Total', 'Quantity', 'Cost', 'Type', 'Category',\n",
       "       'Nearest_Station', 'Station_Province', 'Distance_km',\n",
       "       'Max_24hr_Rainfall_mm', 'Total_Storm_Rainfall_mm', 'Min_Pressure_hPa',\n",
       "       'Max_Sustained_Wind_kph', 'Duration_in_PAR_Hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b2a7ac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Typhoon Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Region",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City/Municipality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Families",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Person",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brgy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dead",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Injured/Ill",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Missing",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Totally",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partially",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nearest_Station",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Station_Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Distance_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Max_24hr_Rainfall_mm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total_Storm_Rainfall_mm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Min_Pressure_hPa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Max_Sustained_Wind_kph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Duration_in_PAR_Hours",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "11e85811-d57b-4bc9-ba46-cf2aa0b649dd",
       "rows": [
        [
         "0",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "BASCO",
         "3608",
         "11120",
         "6",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "3608",
         "2646179.36",
         "['FAMILY FOOD PACK']",
         "['FAMILY FOOD PACK']",
         "BASCO",
         "BATANES",
         "2.497503561",
         null,
         null,
         null,
         null,
         "133.0"
        ],
        [
         "1",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "ITBAYAT",
         "968",
         "3028",
         "5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "966",
         "494592.0",
         "['FAMILY FOOD PACK']",
         "['FAMILY FOOD PACK']",
         "ITBAYAT",
         "BATANES",
         "3.204942957",
         null,
         null,
         null,
         null,
         "133.0"
        ],
        [
         "2",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "IVANA",
         "444",
         "1532",
         "4",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "444",
         "227328.0",
         "['FAMILY FOOD PACK']",
         "['FAMILY FOOD PACK']",
         "BASCO",
         "BATANES",
         "9.470553732",
         null,
         null,
         null,
         null,
         "133.0"
        ],
        [
         "3",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "MAHATAO",
         "575",
         "1792",
         "4",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "575",
         "291082.96",
         "['FAMILY FOOD PACK']",
         "['FAMILY FOOD PACK']",
         "BASCO",
         "BATANES",
         "4.890815627",
         null,
         null,
         null,
         null,
         "133.0"
        ],
        [
         "4",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "SABTANG",
         "575",
         "1955",
         "6",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "575",
         "296521.75",
         "['FAMILY FOOD PACK']",
         "['FAMILY FOOD PACK']",
         "BASCO",
         "BATANES",
         "19.89123103",
         null,
         null,
         null,
         null,
         "133.0"
        ]
       ],
       "shape": {
        "columns": 26,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typhoon Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Region</th>\n",
       "      <th>Province</th>\n",
       "      <th>City/Municipality</th>\n",
       "      <th>Families</th>\n",
       "      <th>Person</th>\n",
       "      <th>Brgy</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Injured/Ill</th>\n",
       "      <th>...</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Nearest_Station</th>\n",
       "      <th>Station_Province</th>\n",
       "      <th>Distance_km</th>\n",
       "      <th>Max_24hr_Rainfall_mm</th>\n",
       "      <th>Total_Storm_Rainfall_mm</th>\n",
       "      <th>Min_Pressure_hPa</th>\n",
       "      <th>Max_Sustained_Wind_kph</th>\n",
       "      <th>Duration_in_PAR_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>3608</td>\n",
       "      <td>11120</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>2.497504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>ITBAYAT</td>\n",
       "      <td>968</td>\n",
       "      <td>3028</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>ITBAYAT</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>3.204943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>IVANA</td>\n",
       "      <td>444</td>\n",
       "      <td>1532</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>9.470554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>MAHATAO</td>\n",
       "      <td>575</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>4.890816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>SABTANG</td>\n",
       "      <td>575</td>\n",
       "      <td>1955</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>['FAMILY FOOD PACK']</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>19.891231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Typhoon Name  Year  Region Province City/Municipality  Families  Person  \\\n",
       "0        BETTY  2023       2  BATANES             BASCO      3608   11120   \n",
       "1        BETTY  2023       2  BATANES           ITBAYAT       968    3028   \n",
       "2        BETTY  2023       2  BATANES             IVANA       444    1532   \n",
       "3        BETTY  2023       2  BATANES           MAHATAO       575    1792   \n",
       "4        BETTY  2023       2  BATANES           SABTANG       575    1955   \n",
       "\n",
       "   Brgy  Dead  Injured/Ill  ...                  Type              Category  \\\n",
       "0     6     0            0  ...  ['FAMILY FOOD PACK']  ['FAMILY FOOD PACK']   \n",
       "1     5     0            0  ...  ['FAMILY FOOD PACK']  ['FAMILY FOOD PACK']   \n",
       "2     4     0            0  ...  ['FAMILY FOOD PACK']  ['FAMILY FOOD PACK']   \n",
       "3     4     0            0  ...  ['FAMILY FOOD PACK']  ['FAMILY FOOD PACK']   \n",
       "4     6     0            0  ...  ['FAMILY FOOD PACK']  ['FAMILY FOOD PACK']   \n",
       "\n",
       "   Nearest_Station  Station_Province  Distance_km  Max_24hr_Rainfall_mm  \\\n",
       "0            BASCO           BATANES     2.497504                   NaN   \n",
       "1          ITBAYAT           BATANES     3.204943                   NaN   \n",
       "2            BASCO           BATANES     9.470554                   NaN   \n",
       "3            BASCO           BATANES     4.890816                   NaN   \n",
       "4            BASCO           BATANES    19.891231                   NaN   \n",
       "\n",
       "  Total_Storm_Rainfall_mm Min_Pressure_hPa Max_Sustained_Wind_kph  \\\n",
       "0                     NaN              NaN                    NaN   \n",
       "1                     NaN              NaN                    NaN   \n",
       "2                     NaN              NaN                    NaN   \n",
       "3                     NaN              NaN                    NaN   \n",
       "4                     NaN              NaN                    NaN   \n",
       "\n",
       "  Duration_in_PAR_Hours  \n",
       "0                 133.0  \n",
       "1                 133.0  \n",
       "2                 133.0  \n",
       "3                 133.0  \n",
       "4                 133.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "64e8ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_data.drop(columns=['Type', 'Category', 'Max_24hr_Rainfall_mm', 'Total_Storm_Rainfall_mm', 'Min_Pressure_hPa', 'Max_Sustained_Wind_kph'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "ec782d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Typhoon Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Region",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City/Municipality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Families",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Person",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brgy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dead",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Injured/Ill",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Missing",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Totally",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partially",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Nearest_Station",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Station_Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Distance_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Duration_in_PAR_Hours",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a4071165-ac64-4b01-9a5b-c8a8cbd5adb6",
       "rows": [
        [
         "0",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "BASCO",
         "3608",
         "11120",
         "6",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "3608",
         "2646179.36",
         "BASCO",
         "BATANES",
         "2.497503561",
         "133.0"
        ],
        [
         "1",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "ITBAYAT",
         "968",
         "3028",
         "5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "966",
         "494592.0",
         "ITBAYAT",
         "BATANES",
         "3.204942957",
         "133.0"
        ],
        [
         "2",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "IVANA",
         "444",
         "1532",
         "4",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "444",
         "227328.0",
         "BASCO",
         "BATANES",
         "9.470553732",
         "133.0"
        ],
        [
         "3",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "MAHATAO",
         "575",
         "1792",
         "4",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "575",
         "291082.96",
         "BASCO",
         "BATANES",
         "4.890815627",
         "133.0"
        ],
        [
         "4",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "SABTANG",
         "575",
         "1955",
         "6",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "575",
         "296521.75",
         "BASCO",
         "BATANES",
         "19.89123103",
         "133.0"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typhoon Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Region</th>\n",
       "      <th>Province</th>\n",
       "      <th>City/Municipality</th>\n",
       "      <th>Families</th>\n",
       "      <th>Person</th>\n",
       "      <th>Brgy</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Injured/Ill</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Totally</th>\n",
       "      <th>Partially</th>\n",
       "      <th>Total</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Nearest_Station</th>\n",
       "      <th>Station_Province</th>\n",
       "      <th>Distance_km</th>\n",
       "      <th>Duration_in_PAR_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>3608</td>\n",
       "      <td>11120</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3608</td>\n",
       "      <td>2646179.36</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>2.497504</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>ITBAYAT</td>\n",
       "      <td>968</td>\n",
       "      <td>3028</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>966</td>\n",
       "      <td>494592.00</td>\n",
       "      <td>ITBAYAT</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>3.204943</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>IVANA</td>\n",
       "      <td>444</td>\n",
       "      <td>1532</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>444</td>\n",
       "      <td>227328.00</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>9.470554</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>MAHATAO</td>\n",
       "      <td>575</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "      <td>291082.96</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>4.890816</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>SABTANG</td>\n",
       "      <td>575</td>\n",
       "      <td>1955</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "      <td>296521.75</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>19.891231</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Typhoon Name  Year  Region Province City/Municipality  Families  Person  \\\n",
       "0        BETTY  2023       2  BATANES             BASCO      3608   11120   \n",
       "1        BETTY  2023       2  BATANES           ITBAYAT       968    3028   \n",
       "2        BETTY  2023       2  BATANES             IVANA       444    1532   \n",
       "3        BETTY  2023       2  BATANES           MAHATAO       575    1792   \n",
       "4        BETTY  2023       2  BATANES           SABTANG       575    1955   \n",
       "\n",
       "   Brgy  Dead  Injured/Ill  Missing  Totally  Partially  Total  Quantity  \\\n",
       "0     6     0            0        0        0          0      0      3608   \n",
       "1     5     0            0        0        0          0      0       966   \n",
       "2     4     0            0        0        0          0      0       444   \n",
       "3     4     0            0        0        0          0      0       575   \n",
       "4     6     0            0        0        0          0      0       575   \n",
       "\n",
       "         Cost Nearest_Station Station_Province  Distance_km  \\\n",
       "0  2646179.36           BASCO          BATANES     2.497504   \n",
       "1   494592.00         ITBAYAT          BATANES     3.204943   \n",
       "2   227328.00           BASCO          BATANES     9.470554   \n",
       "3   291082.96           BASCO          BATANES     4.890816   \n",
       "4   296521.75           BASCO          BATANES    19.891231   \n",
       "\n",
       "   Duration_in_PAR_Hours  \n",
       "0                  133.0  \n",
       "1                  133.0  \n",
       "2                  133.0  \n",
       "3                  133.0  \n",
       "4                  133.0  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf87250",
   "metadata": {},
   "source": [
    "## Join Impact Data with Duration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "b3a86e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique typhoons in impact_data:\n",
      "Count: 25\n",
      "['AGATON', 'AMANG', 'AMBO', 'BETTY', 'DANTE', 'DODONG', 'ESTER', 'FABIAN', 'FLORITA', 'HENRY', 'JENNY', 'JOLINA', 'KABAYAN', 'KARDING', 'KIKO', 'MARING', 'MAYMAY', 'NENENG', 'OBET', 'ODETTE', 'OFEL', 'PAENG', 'PEPITO', 'QUINTA', 'ROLLY']\n",
      "\n",
      "Unique typhoons in duration_data:\n",
      "Count: 69\n",
      "['AGATON', 'AGHON', 'AMANG', 'AMBO', 'AURING', 'BASYANG', 'BETTY', 'BISING', 'BUTCHOY', 'CALOY', 'CARINA', 'CHEDENG', 'CRISING', 'DANTE', 'DINDO', 'DODONG', 'DOMENG', 'EGAY', 'EMONG', 'ENTENG', 'ESTER', 'FABIAN', 'FALCON', 'FERDIE', 'FLORITA', 'GARDO', 'GENER', 'GORING', 'GORIO', 'HANNA', 'HELEN', 'HENRY', 'HUANING', 'IGME', 'INDAY', 'INENG', 'ISANG', 'JENNY', 'JOLINA', 'JOSIE', 'JULIAN', 'KABAYAN', 'KARDING', 'KIKO', 'KRISTINE', 'LANNIE', 'LEON', 'LUIS', 'MARCE', 'MARING', 'MAYMAY', 'NANDO', 'NENENG', 'NIKA', 'OBET', 'ODETTE', 'OFEL', 'PAENG', 'PEPITO', 'QUEENIE', 'QUERUBIN', 'QUINTA', 'ROLLY', 'ROMINA', 'ROSAL', 'SIONY', 'TONYO', 'ULYSSES', 'VICKY']\n",
      "\n",
      "Matching typhoons: 25\n",
      "Missing in duration_data: 0 - []\n",
      "Missing in impact_data: 44 - ['AGHON', 'AURING', 'BASYANG', 'BISING', 'BUTCHOY', 'CALOY', 'CARINA', 'CHEDENG', 'CRISING', 'DINDO', 'DOMENG', 'EGAY', 'EMONG', 'ENTENG', 'FALCON', 'FERDIE', 'GARDO', 'GENER', 'GORING', 'GORIO', 'HANNA', 'HELEN', 'HUANING', 'IGME', 'INDAY', 'INENG', 'ISANG', 'JOSIE', 'JULIAN', 'KRISTINE', 'LANNIE', 'LEON', 'LUIS', 'MARCE', 'NANDO', 'NIKA', 'QUEENIE', 'QUERUBIN', 'ROMINA', 'ROSAL', 'SIONY', 'TONYO', 'ULYSSES', 'VICKY']\n"
     ]
    }
   ],
   "source": [
    "# First, let's examine the typhoon names in both datasets to understand matching\n",
    "print(\"Unique typhoons in impact_data:\")\n",
    "impact_typhoons = set(impact_data['Typhoon Name'].str.upper().unique())\n",
    "print(f\"Count: {len(impact_typhoons)}\")\n",
    "print(sorted(impact_typhoons))\n",
    "\n",
    "print(\"\\nUnique typhoons in duration_data:\")\n",
    "duration_typhoons = set(duration_data['TC NAME'].str.upper().unique())\n",
    "print(f\"Count: {len(duration_typhoons)}\")\n",
    "print(sorted(duration_typhoons))\n",
    "\n",
    "# Check which typhoons match\n",
    "matching_typhoons = impact_typhoons.intersection(duration_typhoons)\n",
    "missing_in_duration = impact_typhoons - duration_typhoons\n",
    "missing_in_impact = duration_typhoons - impact_typhoons\n",
    "\n",
    "print(f\"\\nMatching typhoons: {len(matching_typhoons)}\")\n",
    "print(f\"Missing in duration_data: {len(missing_in_duration)} - {sorted(missing_in_duration)}\")\n",
    "print(f\"Missing in impact_data: {len(missing_in_impact)} - {sorted(missing_in_impact)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "c3523f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation completed!\n",
      "Duration data with valid dates: 84\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for joining\n",
    "# Clean and standardize typhoon names and years\n",
    "impact_data_clean = impact_data.copy()\n",
    "duration_data_clean = duration_data.copy()\n",
    "\n",
    "# Standardize typhoon names (convert to uppercase for matching)\n",
    "impact_data_clean['Typhoon_Name_Clean'] = impact_data_clean['Typhoon Name'].str.strip().str.upper()\n",
    "duration_data_clean['TC_Name_Clean'] = duration_data_clean['TC NAME'].str.strip().str.upper()\n",
    "\n",
    "# Convert date columns in duration_data\n",
    "duration_data_clean['PAR_START'] = pd.to_datetime(duration_data_clean['PAR BEG'], format='%m/%d/%Y', errors='coerce')\n",
    "duration_data_clean['PAR_END'] = pd.to_datetime(duration_data_clean['PAR END'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "print(\"Data preparation completed!\")\n",
    "print(f\"Duration data with valid dates: {duration_data_clean.dropna(subset=['PAR_START', 'PAR_END']).shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "be4cf082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original impact data: 1776 records\n",
      "Merged data: 1776 records\n",
      "Records with duration data: 1776\n",
      "Records without duration data: 0\n",
      "\n",
      "Sample of merged data:\n",
      "  Typhoon Name  Year Province  PAR_START    PAR_END  MSW TYPE\n",
      "0        BETTY  2023  BATANES 2023-05-27 2023-06-01  195  STY\n",
      "1        BETTY  2023  BATANES 2023-05-27 2023-06-01  195  STY\n",
      "2        BETTY  2023  BATANES 2023-05-27 2023-06-01  195  STY\n",
      "3        BETTY  2023  BATANES 2023-05-27 2023-06-01  195  STY\n",
      "4        BETTY  2023  BATANES 2023-05-27 2023-06-01  195  STY\n",
      "5        BETTY  2023  BATANES 2023-05-27 2023-06-01  195  STY\n",
      "6        HENRY  2022  BATANES 2022-08-31 2022-09-04  195  STY\n",
      "7        JENNY  2023  BATANES 2023-09-29 2023-10-06  175   TY\n",
      "8        JENNY  2023  BATANES 2023-09-29 2023-10-06  175   TY\n",
      "9        JENNY  2023  BATANES 2023-09-29 2023-10-06  175   TY\n"
     ]
    }
   ],
   "source": [
    "# Perform the join\n",
    "merged_data = impact_data_clean.merge(\n",
    "    duration_data_clean[['YEAR', 'TC_Name_Clean', 'PAR_START', 'PAR_END', 'MSW', 'TYPE']],\n",
    "    left_on=['Year', 'Typhoon_Name_Clean'],\n",
    "    right_on=['YEAR', 'TC_Name_Clean'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Original impact data: {len(impact_data_clean)} records\")\n",
    "print(f\"Merged data: {len(merged_data)} records\")\n",
    "\n",
    "# Check how many records got duration data\n",
    "records_with_duration = merged_data['PAR_START'].notna().sum()\n",
    "print(f\"Records with duration data: {records_with_duration}\")\n",
    "print(f\"Records without duration data: {len(merged_data) - records_with_duration}\")\n",
    "\n",
    "# Display sample of merged data\n",
    "print(\"\\nSample of merged data:\")\n",
    "sample_cols = ['Typhoon Name', 'Year', 'Province', 'PAR_START', 'PAR_END', 'MSW', 'TYPE']\n",
    "available_cols = [col for col in sample_cols if col in merged_data.columns]\n",
    "print(merged_data[available_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "aaf9db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged dataset shape: (1776, 24)\n",
      "\n",
      "Columns in final dataset: ['Typhoon Name', 'Year', 'Region', 'Province', 'City/Municipality', 'Families', 'Person', 'Brgy', 'Dead', 'Injured/Ill', 'Missing', 'Totally', 'Partially', 'Total', 'Quantity', 'Cost', 'Nearest_Station', 'Station_Province', 'Distance_km', 'Duration_in_PAR_Hours', 'PAR_START', 'PAR_END', 'Max_Sustained_Wind_kph', 'Typhoon_Type']\n",
      "\n",
      "Distribution by Typhoon Type:\n",
      "Typhoon_Type\n",
      "STY    504\n",
      "STS    503\n",
      "TY     468\n",
      "TS     234\n",
      "TD      67\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary statistics for new columns:\n",
      "       Duration_in_PAR_Hours  Max_Sustained_Wind_kph\n",
      "count            1776.000000             1776.000000\n",
      "mean              117.337669              139.304617\n",
      "std                37.039775               50.960721\n",
      "min                39.000000               45.000000\n",
      "25%                91.000000              110.000000\n",
      "50%               122.000000              120.000000\n",
      "75%               124.700000              195.000000\n",
      "max               198.000000              225.000000\n"
     ]
    }
   ],
   "source": [
    "# Clean up the merged dataset\n",
    "# Drop temporary columns used for matching\n",
    "final_merged_data = merged_data.drop(columns=['Typhoon_Name_Clean', 'TC_Name_Clean', 'YEAR'], errors='ignore')\n",
    "\n",
    "# Rename columns for clarity\n",
    "column_renames = {\n",
    "    'TYPE': 'Typhoon_Type',\n",
    "    'MSW': 'Max_Sustained_Wind_kph',\n",
    "    'DURATION_HOURS': 'Duration_in_PAR_Hours'\n",
    "}\n",
    "final_merged_data = final_merged_data.rename(columns=column_renames)\n",
    "\n",
    "print(f\"Final merged dataset shape: {final_merged_data.shape}\")\n",
    "print(f\"\\nColumns in final dataset: {final_merged_data.columns.tolist()}\")\n",
    "\n",
    "# Show distribution by typhoon type\n",
    "if 'Typhoon_Type' in final_merged_data.columns:\n",
    "    print(\"\\nDistribution by Typhoon Type:\")\n",
    "    print(final_merged_data['Typhoon_Type'].value_counts())\n",
    "\n",
    "# Show summary statistics for new columns\n",
    "numeric_cols = ['Duration_in_PAR_Hours', 'Max_Sustained_Wind_kph']\n",
    "available_numeric = [col for col in numeric_cols if col in final_merged_data.columns]\n",
    "if available_numeric:\n",
    "    print(\"\\nSummary statistics for new columns:\")\n",
    "    print(final_merged_data[available_numeric].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "c1836c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Typhoon Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Region",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City/Municipality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Families",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Person",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brgy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dead",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Injured/Ill",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Missing",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Totally",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partially",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Nearest_Station",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Station_Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Distance_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Duration_in_PAR_Hours",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PAR_START",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "PAR_END",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Max_Sustained_Wind_kph",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Typhoon_Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d4120e35-efe3-479b-b612-78d253a312d8",
       "rows": [
        [
         "0",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "BASCO",
         "3608",
         "11120",
         "6",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "3608",
         "2646179.36",
         "BASCO",
         "BATANES",
         "2.497503561",
         "133.0",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "195",
         "STY"
        ],
        [
         "1",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "ITBAYAT",
         "968",
         "3028",
         "5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "966",
         "494592.0",
         "ITBAYAT",
         "BATANES",
         "3.204942957",
         "133.0",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "195",
         "STY"
        ],
        [
         "2",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "IVANA",
         "444",
         "1532",
         "4",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "444",
         "227328.0",
         "BASCO",
         "BATANES",
         "9.470553732",
         "133.0",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "195",
         "STY"
        ],
        [
         "3",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "MAHATAO",
         "575",
         "1792",
         "4",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "575",
         "291082.96",
         "BASCO",
         "BATANES",
         "4.890815627",
         "133.0",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "195",
         "STY"
        ],
        [
         "4",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "SABTANG",
         "575",
         "1955",
         "6",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "575",
         "296521.75",
         "BASCO",
         "BATANES",
         "19.89123103",
         "133.0",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "195",
         "STY"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typhoon Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Region</th>\n",
       "      <th>Province</th>\n",
       "      <th>City/Municipality</th>\n",
       "      <th>Families</th>\n",
       "      <th>Person</th>\n",
       "      <th>Brgy</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Injured/Ill</th>\n",
       "      <th>...</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Nearest_Station</th>\n",
       "      <th>Station_Province</th>\n",
       "      <th>Distance_km</th>\n",
       "      <th>Duration_in_PAR_Hours</th>\n",
       "      <th>PAR_START</th>\n",
       "      <th>PAR_END</th>\n",
       "      <th>Max_Sustained_Wind_kph</th>\n",
       "      <th>Typhoon_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>3608</td>\n",
       "      <td>11120</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3608</td>\n",
       "      <td>2646179.36</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>2.497504</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>ITBAYAT</td>\n",
       "      <td>968</td>\n",
       "      <td>3028</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>966</td>\n",
       "      <td>494592.00</td>\n",
       "      <td>ITBAYAT</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>3.204943</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>IVANA</td>\n",
       "      <td>444</td>\n",
       "      <td>1532</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>444</td>\n",
       "      <td>227328.00</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>9.470554</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>MAHATAO</td>\n",
       "      <td>575</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>575</td>\n",
       "      <td>291082.96</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>4.890816</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>SABTANG</td>\n",
       "      <td>575</td>\n",
       "      <td>1955</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>575</td>\n",
       "      <td>296521.75</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>19.891231</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Typhoon Name  Year  Region Province City/Municipality  Families  Person  \\\n",
       "0        BETTY  2023       2  BATANES             BASCO      3608   11120   \n",
       "1        BETTY  2023       2  BATANES           ITBAYAT       968    3028   \n",
       "2        BETTY  2023       2  BATANES             IVANA       444    1532   \n",
       "3        BETTY  2023       2  BATANES           MAHATAO       575    1792   \n",
       "4        BETTY  2023       2  BATANES           SABTANG       575    1955   \n",
       "\n",
       "   Brgy  Dead  Injured/Ill  ...  Quantity        Cost  Nearest_Station  \\\n",
       "0     6     0            0  ...      3608  2646179.36            BASCO   \n",
       "1     5     0            0  ...       966   494592.00          ITBAYAT   \n",
       "2     4     0            0  ...       444   227328.00            BASCO   \n",
       "3     4     0            0  ...       575   291082.96            BASCO   \n",
       "4     6     0            0  ...       575   296521.75            BASCO   \n",
       "\n",
       "   Station_Province  Distance_km  Duration_in_PAR_Hours  PAR_START    PAR_END  \\\n",
       "0           BATANES     2.497504                  133.0 2023-05-27 2023-06-01   \n",
       "1           BATANES     3.204943                  133.0 2023-05-27 2023-06-01   \n",
       "2           BATANES     9.470554                  133.0 2023-05-27 2023-06-01   \n",
       "3           BATANES     4.890816                  133.0 2023-05-27 2023-06-01   \n",
       "4           BATANES    19.891231                  133.0 2023-05-27 2023-06-01   \n",
       "\n",
       "   Max_Sustained_Wind_kph  Typhoon_Type  \n",
       "0                     195           STY  \n",
       "1                     195           STY  \n",
       "2                     195           STY  \n",
       "3                     195           STY  \n",
       "4                     195           STY  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb8ba1",
   "metadata": {},
   "source": [
    "## Extract Extreme Weather Data During Typhoon Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "ee108f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data columns:\n",
      "['Date(UTC)', 'Aparri, Cagayan Prec.Sum.Dly [mm]', 'Aparri, Cagayan Press.QFF.Min.Dly [hPa]', 'Aparri, Cagayan Wind.Speed.Dly [m/s]', 'Aparri, Cagayan Wind.Dir.Prevailing.Dly [deg.]', 'Baler (Radar), Aurora Prec.Sum.Dly [mm]', 'Baler (Radar), Aurora Press.QFF.Min.Dly [hPa]', 'Baler (Radar), Aurora Wind.Speed.Dly [m/s]', 'Baler (Radar), Aurora Wind.Dir.Prevailing.Dly [deg.]', 'Basco (Radar), Batanes Prec.Sum.Dly [mm]', 'Basco (Radar), Batanes Press.QFF.Min.Dly [hPa]', 'Basco (Radar), Batanes Wind.Speed.Dly [m/s]', 'Basco (Radar), Batanes Wind.Dir.Prevailing.Dly [deg.]', 'Borongan, Eastern Samar Prec.Sum.Dly [mm]', 'Borongan, Eastern Samar Press.QFF.Min.Dly [hPa]', 'Borongan, Eastern Samar Wind.Speed.Dly [m/s]', 'Borongan, Eastern Samar Wind.Dir.Prevailing.Dly [deg.]', 'Calayan, Cagayan Prec.Sum.Dly [mm]', 'Calayan, Cagayan Press.QFF.Min.Dly [hPa]', 'Calayan, Cagayan Wind.Speed.Dly [m/s]']\n",
      "\n",
      "Weather data date range: 2020-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "Total weather records: 1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodney Lei Estrada\\AppData\\Local\\Temp\\ipykernel_7228\\3833653879.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  weather_data_clean['Date'] = pd.to_datetime(weather_data_clean['Date(UTC)'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# First, let's examine the weather data structure\n",
    "print(\"Weather data columns:\")\n",
    "print(weather_data.columns[:20].tolist())  # Show first 20 columns\n",
    "\n",
    "# Clean weather data date column\n",
    "weather_data_clean = weather_data.copy()\n",
    "weather_data_clean['Date'] = pd.to_datetime(weather_data_clean['Date(UTC)'], errors='coerce')\n",
    "\n",
    "# Remove rows with invalid dates\n",
    "weather_data_clean = weather_data_clean.dropna(subset=['Date'])\n",
    "\n",
    "print(f\"\\nWeather data date range: {weather_data_clean['Date'].min()} to {weather_data_clean['Date'].max()}\")\n",
    "print(f\"Total weather records: {len(weather_data_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1ecc9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 weather stations:\n",
      " 1. Aparri:\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      " 2. Baler (Radar):\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      " 3. Basco (Radar):\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      " 4. Borongan:\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      " 5. Calayan:\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      " 6. Casiguran:\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      " 7. Catarman:\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      " 8. Catbalogan:\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      " 9. Clark Airport (DMIA):\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      "10. CLSU Muñoz:\n",
      "    Rainfall: ✓\n",
      "    Pressure: ✓\n",
      "    Wind Speed: ✓\n",
      "... and 12 more stations\n"
     ]
    }
   ],
   "source": [
    "# Function to extract station names and their weather data columns\n",
    "def extract_weather_stations_and_columns(weather_df):\n",
    "    \"\"\"Extract station names and their corresponding weather data columns\"\"\"\n",
    "    stations_info = {}\n",
    "    \n",
    "    for col in weather_df.columns:\n",
    "        if col != 'Date(UTC)' and col != 'Date' and ',' in col:\n",
    "            parts = col.split(',')\n",
    "            if len(parts) >= 2:\n",
    "                station = parts[0].strip()\n",
    "                metric = parts[1].strip()\n",
    "                \n",
    "                if station not in stations_info:\n",
    "                    stations_info[station] = {\n",
    "                        'rainfall': None,\n",
    "                        'pressure': None,\n",
    "                        'wind_speed': None\n",
    "                    }\n",
    "                \n",
    "                # Map metric types to our standard names\n",
    "                if 'Prec.Sum.Dly [mm]' in metric:\n",
    "                    stations_info[station]['rainfall'] = col\n",
    "                elif 'Press.QFF.Min.Dly [hPa]' in metric:\n",
    "                    stations_info[station]['pressure'] = col\n",
    "                elif 'Wind.Speed.Dly [m/s]' in metric:\n",
    "                    stations_info[station]['wind_speed'] = col\n",
    "    \n",
    "    return stations_info\n",
    "\n",
    "# Extract station information\n",
    "stations_info = extract_weather_stations_and_columns(weather_data_clean)\n",
    "\n",
    "print(f\"Found {len(stations_info)} weather stations:\")\n",
    "for i, (station, metrics) in enumerate(list(stations_info.items())[:10], 1):\n",
    "    print(f\"{i:2d}. {station}:\")\n",
    "    print(f\"    Rainfall: {'✓' if metrics['rainfall'] else '✗'}\")\n",
    "    print(f\"    Pressure: {'✓' if metrics['pressure'] else '✗'}\")\n",
    "    print(f\"    Wind Speed: {'✓' if metrics['wind_speed'] else '✗'}\")\n",
    "    \n",
    "if len(stations_info) > 10:\n",
    "    print(f\"... and {len(stations_info) - 10} more stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "e400eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test extraction for Aparri:\n",
      "  Max_24hr_Rainfall_mm: 23.0\n",
      "  Total_Storm_Rainfall_mm: 70.1\n",
      "  Min_Pressure_hPa: 1005.0\n",
      "  records_found: 5\n",
      "  days_covered: 5\n"
     ]
    }
   ],
   "source": [
    "def extract_extreme_weather_for_typhoon(weather_df, station_name, start_date, end_date, stations_info):\n",
    "    \"\"\"\n",
    "    Extract extreme weather values for a specific station during a typhoon period\n",
    "    \n",
    "    Returns:\n",
    "    - Max_24hr_Rainfall_mm: Highest single day rainfall\n",
    "    - Total_Storm_Rainfall_mm: Total accumulated rainfall over storm duration\n",
    "    - Min_Pressure_hPa: Lowest pressure recorded\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {\n",
    "        'Max_24hr_Rainfall_mm': np.nan,\n",
    "        'Total_Storm_Rainfall_mm': np.nan,\n",
    "        'Min_Pressure_hPa': np.nan,\n",
    "        'records_found': 0,\n",
    "        'days_covered': 0\n",
    "    }\n",
    "    \n",
    "    # Check if station exists in our station info\n",
    "    if station_name not in stations_info:\n",
    "        return results\n",
    "    \n",
    "    station_metrics = stations_info[station_name]\n",
    "    \n",
    "    # Filter weather data for the typhoon period\n",
    "    mask = (weather_df['Date'] >= start_date) & (weather_df['Date'] <= end_date)\n",
    "    period_data = weather_df[mask].copy()\n",
    "    \n",
    "    if period_data.empty:\n",
    "        return results\n",
    "    \n",
    "    results['records_found'] = len(period_data)\n",
    "    results['days_covered'] = (end_date - start_date).days + 1\n",
    "    \n",
    "    # Extract rainfall data\n",
    "    if station_metrics['rainfall'] and station_metrics['rainfall'] in period_data.columns:\n",
    "        rainfall_col = station_metrics['rainfall']\n",
    "        rainfall_data = pd.to_numeric(period_data[rainfall_col], errors='coerce')\n",
    "        \n",
    "        # Remove NaN and negative values\n",
    "        rainfall_data = rainfall_data[rainfall_data >= 0]\n",
    "        \n",
    "        if not rainfall_data.empty:\n",
    "            results['Max_24hr_Rainfall_mm'] = rainfall_data.max()\n",
    "            results['Total_Storm_Rainfall_mm'] = rainfall_data.sum()\n",
    "    \n",
    "    # Extract pressure data\n",
    "    if station_metrics['pressure'] and station_metrics['pressure'] in period_data.columns:\n",
    "        pressure_col = station_metrics['pressure']\n",
    "        pressure_data = pd.to_numeric(period_data[pressure_col], errors='coerce')\n",
    "        \n",
    "        # Remove NaN and unrealistic values (pressure should be between 800-1100 hPa)\n",
    "        pressure_data = pressure_data[(pressure_data >= 800) & (pressure_data <= 1100)]\n",
    "        \n",
    "        if not pressure_data.empty:\n",
    "            results['Min_Pressure_hPa'] = pressure_data.min()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the function with a sample\n",
    "if len(stations_info) > 0:\n",
    "    test_station = list(stations_info.keys())[0]\n",
    "    test_start = pd.Timestamp('2020-10-01')\n",
    "    test_end = pd.Timestamp('2020-10-05')\n",
    "    \n",
    "    test_result = extract_extreme_weather_for_typhoon(\n",
    "        weather_data_clean, test_station, test_start, test_end, stations_info\n",
    "    )\n",
    "    \n",
    "    print(f\"Test extraction for {test_station}:\")\n",
    "    for key, value in test_result.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "7315b7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating station mapping...\n",
      "Impact data stations: 22Impact data stations: 22\n",
      "Weather data stations: 22\n",
      "=== CREATING CORRECTED STATION MAPPING ===\n",
      "Available weather stations:\n",
      "   1. 'Aparri'\n",
      "   2. 'Baler (Radar)'\n",
      "   3. 'Basco (Radar)'\n",
      "   4. 'Borongan'\n",
      "   5. 'CLSU Muñoz'\n",
      "   6. 'Calayan'\n",
      "   7. 'Casiguran'\n",
      "   8. 'Catarman'\n",
      "   9. 'Catbalogan'\n",
      "  10. 'Clark Airport (DMIA)'\n",
      "  11. 'Cubi Pt.'\n",
      "  12. 'Daet'\n",
      "  13. 'Guiuan'\n",
      "  14. 'Iba'\n",
      "  15. 'Itbayat'\n",
      "  16. 'Juban'\n",
      "  17. 'Legazpi City'\n",
      "  18. 'Maasin'\n",
      "  19. 'Masbate City'\n",
      "  20. 'Tacloban City'\n",
      "  21. 'Tuguegarao City'\n",
      "  22. 'Virac (Synop)'\n",
      "\n",
      "Corrected manual mappings defined: 35\n",
      "  ✓ Mapped: 'BASCO' → 'Basco (Radar)'\n",
      "  ✓ Mapped: 'ITBAYAT' → 'Itbayat'\n",
      "  ✓ Mapped: 'CALAYAN' → 'Calayan'\n",
      "  ✓ Mapped: 'APARRI' → 'Aparri'\n",
      "  ✓ Mapped: 'TUGUEGARAO' → 'Tuguegarao City'\n",
      "  ✓ Mapped: 'CASIGURAN' → 'Casiguran'\n",
      "  ✓ Mapped: 'BALER' → 'Baler (Radar)'\n",
      "  ✓ Mapped: 'CABANATUAN' → 'CLSU Muñoz'\n",
      "  ✓ Mapped: 'SUBIC BAY' → 'Cubi Pt.'\n",
      "  ✓ Mapped: 'CLARK AIRPORT' → 'Clark Airport (DMIA)'\n",
      "  ✓ Mapped: 'IBA' → 'Iba'\n",
      "  ✓ Mapped: 'LEGAZPI CITY' → 'Legazpi City'\n",
      "  ✓ Mapped: 'DAET' → 'Daet'\n",
      "  ✓ Mapped: 'VIRAC' → 'Virac (Synop)'\n",
      "  ✓ Mapped: 'MASBATE' → 'Masbate City'\n",
      "  ✓ Mapped: 'JUBAN' → 'Juban'\n",
      "  ✓ Mapped: 'CATBALOGAN' → 'Catbalogan'\n",
      "  ✓ Mapped: 'TACLOBAN' → 'Tacloban City'\n",
      "  ✓ Mapped: 'BORONGAN' → 'Borongan'\n",
      "  ✓ Mapped: 'GUIUAN' → 'Guiuan'\n",
      "  ✓ Mapped: 'MAASIN' → 'Maasin'\n",
      "  ✓ Mapped: 'CATARMAN' → 'Catarman'\n",
      "\n",
      "Mapping Results:\n",
      "  Successful mappings: 22\n",
      "  Failed mappings: 0\n",
      "\n",
      "=== CORRECTED MAPPING SUMMARY ===\n",
      "Corrected station mappings found: 22\n",
      "Previous mappings: 22\n",
      "Improvement: +0 mappings\n",
      "\n",
      "=== VERIFICATION FOR PROBLEM STATIONS ===\n",
      "  Nueva Ecija: 'CABANATUAN' → 'CLSU Muñoz'\n",
      "  Subic Bay: 'SUBIC BAY' → 'Cubi Pt.'\n",
      "\n",
      "Still unmapped stations (0):\n",
      "\n",
      "Weather data stations: 22\n",
      "=== CREATING CORRECTED STATION MAPPING ===\n",
      "Available weather stations:\n",
      "   1. 'Aparri'\n",
      "   2. 'Baler (Radar)'\n",
      "   3. 'Basco (Radar)'\n",
      "   4. 'Borongan'\n",
      "   5. 'CLSU Muñoz'\n",
      "   6. 'Calayan'\n",
      "   7. 'Casiguran'\n",
      "   8. 'Catarman'\n",
      "   9. 'Catbalogan'\n",
      "  10. 'Clark Airport (DMIA)'\n",
      "  11. 'Cubi Pt.'\n",
      "  12. 'Daet'\n",
      "  13. 'Guiuan'\n",
      "  14. 'Iba'\n",
      "  15. 'Itbayat'\n",
      "  16. 'Juban'\n",
      "  17. 'Legazpi City'\n",
      "  18. 'Maasin'\n",
      "  19. 'Masbate City'\n",
      "  20. 'Tacloban City'\n",
      "  21. 'Tuguegarao City'\n",
      "  22. 'Virac (Synop)'\n",
      "\n",
      "Corrected manual mappings defined: 35\n",
      "  ✓ Mapped: 'BASCO' → 'Basco (Radar)'\n",
      "  ✓ Mapped: 'ITBAYAT' → 'Itbayat'\n",
      "  ✓ Mapped: 'CALAYAN' → 'Calayan'\n",
      "  ✓ Mapped: 'APARRI' → 'Aparri'\n",
      "  ✓ Mapped: 'TUGUEGARAO' → 'Tuguegarao City'\n",
      "  ✓ Mapped: 'CASIGURAN' → 'Casiguran'\n",
      "  ✓ Mapped: 'BALER' → 'Baler (Radar)'\n",
      "  ✓ Mapped: 'CABANATUAN' → 'CLSU Muñoz'\n",
      "  ✓ Mapped: 'SUBIC BAY' → 'Cubi Pt.'\n",
      "  ✓ Mapped: 'CLARK AIRPORT' → 'Clark Airport (DMIA)'\n",
      "  ✓ Mapped: 'IBA' → 'Iba'\n",
      "  ✓ Mapped: 'LEGAZPI CITY' → 'Legazpi City'\n",
      "  ✓ Mapped: 'DAET' → 'Daet'\n",
      "  ✓ Mapped: 'VIRAC' → 'Virac (Synop)'\n",
      "  ✓ Mapped: 'MASBATE' → 'Masbate City'\n",
      "  ✓ Mapped: 'JUBAN' → 'Juban'\n",
      "  ✓ Mapped: 'CATBALOGAN' → 'Catbalogan'\n",
      "  ✓ Mapped: 'TACLOBAN' → 'Tacloban City'\n",
      "  ✓ Mapped: 'BORONGAN' → 'Borongan'\n",
      "  ✓ Mapped: 'GUIUAN' → 'Guiuan'\n",
      "  ✓ Mapped: 'MAASIN' → 'Maasin'\n",
      "  ✓ Mapped: 'CATARMAN' → 'Catarman'\n",
      "\n",
      "Mapping Results:\n",
      "  Successful mappings: 22\n",
      "  Failed mappings: 0\n",
      "\n",
      "=== CORRECTED MAPPING SUMMARY ===\n",
      "Corrected station mappings found: 22\n",
      "Previous mappings: 22\n",
      "Improvement: +0 mappings\n",
      "\n",
      "=== VERIFICATION FOR PROBLEM STATIONS ===\n",
      "  Nueva Ecija: 'CABANATUAN' → 'CLSU Muñoz'\n",
      "  Subic Bay: 'SUBIC BAY' → 'Cubi Pt.'\n",
      "\n",
      "Still unmapped stations (0):\n"
     ]
    }
   ],
   "source": [
    "# Create mapping between impact data stations and weather data stations\n",
    "print(\"Creating station mapping...\")\n",
    "\n",
    "# Get unique stations from impact data\n",
    "impact_stations = final_merged_data['Nearest_Station'].dropna().unique()\n",
    "weather_stations = list(stations_info.keys())\n",
    "\n",
    "print(f\"Impact data stations: {len(impact_stations)}\")\n",
    "print(f\"Weather data stations: {len(weather_stations)}\")\n",
    "\n",
    "# IMPROVED STATION MAPPING - Fixed with correct weather station names\n",
    "print(\"=== CREATING CORRECTED STATION MAPPING ===\")\n",
    "\n",
    "def create_corrected_station_mapping(impact_stations, weather_stations):\n",
    "    \"\"\"\n",
    "    Create corrected mapping between impact stations and weather stations\n",
    "    Uses the exact short names from stations_info keys\n",
    "    \"\"\"\n",
    "    station_mapping = {}\n",
    "    \n",
    "    # Print actual weather station names first for debugging\n",
    "    print(\"Available weather stations:\")\n",
    "    for i, ws in enumerate(sorted(weather_stations), 1):\n",
    "        print(f\"  {i:2d}. '{ws}'\")\n",
    "    \n",
    "    # CORRECTED Manual mappings using EXACT short weather station names from stations_info\n",
    "    manual_mappings = {\n",
    "        # Nueva Ecija mappings - corrected to match stations_info key\n",
    "        'CABANATUAN': 'CLSU Muñoz',\n",
    "        'MUÑOZ': 'CLSU Muñoz',\n",
    "        'MUNOZ': 'CLSU Muñoz', \n",
    "        'NUEVA ECIJA': 'CLSU Muñoz',\n",
    "        'CLSU': 'CLSU Muñoz',\n",
    "        'CLSU MUNOZ': 'CLSU Muñoz',\n",
    "        'CLSU MUÑOZ': 'CLSU Muñoz',\n",
    "        \n",
    "        # Subic Bay mappings - corrected to match stations_info key\n",
    "        'SUBIC': 'Cubi Pt.',\n",
    "        'SUBIC BAY': 'Cubi Pt.',\n",
    "        'OLONGAPO': 'Cubi Pt.',\n",
    "        'CUBI': 'Cubi Pt.',\n",
    "        'CUBI POINT': 'Cubi Pt.',\n",
    "        'CUBI PT': 'Cubi Pt.',\n",
    "        \n",
    "        # Other mappings - corrected to match stations_info keys\n",
    "        'APARRI': 'Aparri',\n",
    "        'BALER': 'Baler (Radar)', \n",
    "        'BASCO': 'Basco (Radar)',\n",
    "        'BORONGAN': 'Borongan',\n",
    "        'CALAYAN': 'Calayan',\n",
    "        'CASIGURAN': 'Casiguran',\n",
    "        'CATARMAN': 'Catarman',\n",
    "        'CATBALOGAN': 'Catbalogan',\n",
    "        'CLARK': 'Clark Airport (DMIA)',\n",
    "        'CLARK AIRPORT': 'Clark Airport (DMIA)',\n",
    "        'DAET': 'Daet',\n",
    "        'GUIUAN': 'Guiuan',\n",
    "        'IBA': 'Iba',\n",
    "        'ITBAYAT': 'Itbayat',\n",
    "        'JUBAN': 'Juban', \n",
    "        'LEGAZPI': 'Legazpi City',\n",
    "        'LEGAZPI CITY': 'Legazpi City',\n",
    "        'MAASIN': 'Maasin',\n",
    "        'MASBATE': 'Masbate City',\n",
    "        'TACLOBAN': 'Tacloban City',\n",
    "        'TUGUEGARAO': 'Tuguegarao City',\n",
    "        'VIRAC': 'Virac (Synop)'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nCorrected manual mappings defined: {len(manual_mappings)}\")\n",
    "    \n",
    "    # First pass: Manual mappings with exact name verification\n",
    "    successful_mappings = 0\n",
    "    failed_mappings = 0\n",
    "    \n",
    "    for impact_station in impact_stations:\n",
    "        impact_clean = impact_station.strip().upper()\n",
    "        \n",
    "        # Check manual mappings first\n",
    "        if impact_clean in manual_mappings:\n",
    "            target_station = manual_mappings[impact_clean]\n",
    "            if target_station in weather_stations:\n",
    "                station_mapping[impact_station] = target_station\n",
    "                successful_mappings += 1\n",
    "                print(f\"  ✓ Mapped: '{impact_station}' → '{target_station}'\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"  ✗ Target station not found: '{target_station}' for '{impact_station}'\")\n",
    "                failed_mappings += 1\n",
    "        \n",
    "        # Check if impact station is a substring of any manual mapping key\n",
    "        mapped = False\n",
    "        for manual_key, manual_value in manual_mappings.items():\n",
    "            if manual_key in impact_clean or impact_clean in manual_key:\n",
    "                if manual_value in weather_stations:\n",
    "                    station_mapping[impact_station] = manual_value\n",
    "                    successful_mappings += 1\n",
    "                    print(f\"  ✓ Substring mapped: '{impact_station}' → '{manual_value}'\")\n",
    "                    mapped = True\n",
    "                    break\n",
    "        \n",
    "        if mapped:\n",
    "            continue\n",
    "    \n",
    "    # Second pass: Fuzzy matching for unmapped stations\n",
    "    for impact_station in impact_stations:\n",
    "        if impact_station in station_mapping:\n",
    "            continue\n",
    "            \n",
    "        impact_clean = impact_station.strip().upper()\n",
    "        \n",
    "        # Try exact match\n",
    "        for weather_station in weather_stations:\n",
    "            weather_clean = weather_station.strip().upper()\n",
    "            \n",
    "            if impact_clean == weather_clean:\n",
    "                station_mapping[impact_station] = weather_station\n",
    "                successful_mappings += 1\n",
    "                print(f\"  ✓ Exact match: '{impact_station}' → '{weather_station}'\")\n",
    "                break\n",
    "                \n",
    "        # Try partial matches if no exact match found\n",
    "        if impact_station not in station_mapping:\n",
    "            for weather_station in weather_stations:\n",
    "                weather_clean = weather_station.strip().upper()\n",
    "                \n",
    "                # Check if impact station is contained in weather station name\n",
    "                if impact_clean in weather_clean:\n",
    "                    station_mapping[impact_station] = weather_station\n",
    "                    successful_mappings += 1\n",
    "                    print(f\"  ✓ Partial match: '{impact_station}' → '{weather_station}'\")\n",
    "                    break\n",
    "                    \n",
    "                # Check if weather station city/province is contained in impact station\n",
    "                weather_parts = weather_clean.split(',')\n",
    "                if len(weather_parts) > 0:\n",
    "                    weather_city = weather_parts[0].strip()\n",
    "                    if weather_city in impact_clean:\n",
    "                        station_mapping[impact_station] = weather_station\n",
    "                        successful_mappings += 1\n",
    "                        print(f\"  ✓ City match: '{impact_station}' → '{weather_station}'\")\n",
    "                        break\n",
    "    \n",
    "    print(f\"\\nMapping Results:\")\n",
    "    print(f\"  Successful mappings: {successful_mappings}\")\n",
    "    print(f\"  Failed mappings: {failed_mappings}\")\n",
    "    \n",
    "    return station_mapping\n",
    "\n",
    "# Create the corrected mapping\n",
    "corrected_station_mapping = create_corrected_station_mapping(impact_stations, weather_stations)\n",
    "\n",
    "print(f\"\\n=== CORRECTED MAPPING SUMMARY ===\")\n",
    "print(f\"Corrected station mappings found: {len(corrected_station_mapping)}\")\n",
    "if 'station_mapping' in globals():\n",
    "    print(f\"Previous mappings: {len(station_mapping)}\")\n",
    "    print(f\"Improvement: +{len(corrected_station_mapping) - len(station_mapping)} mappings\")\n",
    "\n",
    "# Check specifically for Nueva Ecija and Subic Bay mappings\n",
    "print(f\"\\n=== VERIFICATION FOR PROBLEM STATIONS ===\")\n",
    "nueva_ecija_found = False\n",
    "subic_found = False\n",
    "\n",
    "for impact, weather in corrected_station_mapping.items():\n",
    "    if 'NUEVA ECIJA' in impact.upper() or 'CABANATUAN' in impact.upper() or 'MUÑOZ' in impact.upper() or 'MUNOZ' in impact.upper():\n",
    "        print(f\"  Nueva Ecija: '{impact}' → '{weather}'\")\n",
    "        nueva_ecija_found = True\n",
    "    if 'SUBIC BAY' in impact.upper() or 'OLONGAPO' in impact.upper() or 'CUBI' in impact.upper():\n",
    "        print(f\"  Subic Bay: '{impact}' → '{weather}'\") \n",
    "        subic_found = True\n",
    "\n",
    "if not nueva_ecija_found:\n",
    "    print(f\"  Nueva Ecija: No mappings found\")\n",
    "if not subic_found:\n",
    "    print(f\"  Subic Bay: No mappings found\")\n",
    "\n",
    "# Update the station mapping\n",
    "station_mapping = corrected_station_mapping\n",
    "\n",
    "# Show final unmapped stations\n",
    "still_unmapped = [s for s in impact_stations if s not in station_mapping]\n",
    "print(f\"\\nStill unmapped stations ({len(still_unmapped)}):\")\n",
    "for i, station in enumerate(still_unmapped, 1):\n",
    "    print(f\"  {i:2d}. '{station}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "63004f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STATION MAPPING DIAGNOSIS ===\n",
      "\n",
      "All impact stations (22):\n",
      "   1. 'APARRI'\n",
      "   2. 'BALER'\n",
      "   3. 'BASCO'\n",
      "   4. 'BORONGAN'\n",
      "   5. 'CABANATUAN'\n",
      "   6. 'CALAYAN'\n",
      "   7. 'CASIGURAN'\n",
      "   8. 'CATARMAN'\n",
      "   9. 'CATBALOGAN'\n",
      "  10. 'CLARK AIRPORT'\n",
      "  11. 'DAET'\n",
      "  12. 'GUIUAN'\n",
      "  13. 'IBA'\n",
      "  14. 'ITBAYAT'\n",
      "  15. 'JUBAN'\n",
      "  16. 'LEGAZPI CITY'\n",
      "  17. 'MAASIN'\n",
      "  18. 'MASBATE'\n",
      "  19. 'SUBIC BAY'\n",
      "  20. 'TACLOBAN'\n",
      "  21. 'TUGUEGARAO'\n",
      "  22. 'VIRAC'\n",
      "\n",
      "All weather stations (22):\n",
      "   1. 'Aparri'\n",
      "   2. 'Baler (Radar)'\n",
      "   3. 'Basco (Radar)'\n",
      "   4. 'Borongan'\n",
      "   5. 'CLSU Muñoz'\n",
      "   6. 'Calayan'\n",
      "   7. 'Casiguran'\n",
      "   8. 'Catarman'\n",
      "   9. 'Catbalogan'\n",
      "  10. 'Clark Airport (DMIA)'\n",
      "  11. 'Cubi Pt.'\n",
      "  12. 'Daet'\n",
      "  13. 'Guiuan'\n",
      "  14. 'Iba'\n",
      "  15. 'Itbayat'\n",
      "  16. 'Juban'\n",
      "  17. 'Legazpi City'\n",
      "  18. 'Maasin'\n",
      "  19. 'Masbate City'\n",
      "  20. 'Tacloban City'\n",
      "  21. 'Tuguegarao City'\n",
      "  22. 'Virac (Synop)'\n",
      "\n",
      "Current mappings (22):\n",
      "   1. 'BASCO' → 'Basco (Radar)'\n",
      "   2. 'ITBAYAT' → 'Itbayat'\n",
      "   3. 'CALAYAN' → 'Calayan'\n",
      "   4. 'APARRI' → 'Aparri'\n",
      "   5. 'TUGUEGARAO' → 'Tuguegarao City'\n",
      "   6. 'CASIGURAN' → 'Casiguran'\n",
      "   7. 'BALER' → 'Baler (Radar)'\n",
      "   8. 'CABANATUAN' → 'CLSU Muñoz'\n",
      "   9. 'SUBIC BAY' → 'Cubi Pt.'\n",
      "  10. 'CLARK AIRPORT' → 'Clark Airport (DMIA)'\n",
      "  11. 'IBA' → 'Iba'\n",
      "  12. 'LEGAZPI CITY' → 'Legazpi City'\n",
      "  13. 'DAET' → 'Daet'\n",
      "  14. 'VIRAC' → 'Virac (Synop)'\n",
      "  15. 'MASBATE' → 'Masbate City'\n",
      "  16. 'JUBAN' → 'Juban'\n",
      "  17. 'CATBALOGAN' → 'Catbalogan'\n",
      "  18. 'TACLOBAN' → 'Tacloban City'\n",
      "  19. 'BORONGAN' → 'Borongan'\n",
      "  20. 'GUIUAN' → 'Guiuan'\n",
      "  21. 'MAASIN' → 'Maasin'\n",
      "  22. 'CATARMAN' → 'Catarman'\n",
      "\n",
      "Unmapped impact stations (0):\n"
     ]
    }
   ],
   "source": [
    "# Let's first diagnose the mapping issues\n",
    "print(\"=== STATION MAPPING DIAGNOSIS ===\")\n",
    "\n",
    "# Show all impact stations\n",
    "impact_stations = final_merged_data['Nearest_Station'].dropna().unique()\n",
    "print(f\"\\nAll impact stations ({len(impact_stations)}):\")\n",
    "for i, station in enumerate(sorted(impact_stations), 1):\n",
    "    print(f\"  {i:2d}. '{station}'\")\n",
    "\n",
    "# Show all weather stations\n",
    "weather_stations = list(stations_info.keys())\n",
    "print(f\"\\nAll weather stations ({len(weather_stations)}):\")\n",
    "for i, station in enumerate(sorted(weather_stations), 1):\n",
    "    print(f\"  {i:2d}. '{station}'\")\n",
    "\n",
    "# Show current mappings\n",
    "print(f\"\\nCurrent mappings ({len(station_mapping)}):\")\n",
    "for i, (impact, weather) in enumerate(station_mapping.items(), 1):\n",
    "    print(f\"  {i:2d}. '{impact}' → '{weather}'\")\n",
    "\n",
    "# Show unmapped impact stations\n",
    "unmapped = [s for s in impact_stations if s not in station_mapping]\n",
    "print(f\"\\nUnmapped impact stations ({len(unmapped)}):\")\n",
    "for i, station in enumerate(unmapped, 1):\n",
    "    print(f\"  {i:2d}. '{station}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7a059347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting extreme weather data for each typhoon impact...\n",
      "Processing 1776 records in batches of 100...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 28.2% (500/1776 records)\n",
      "  Progress: 56.3% (1000/1776 records)\n",
      "  Progress: 56.3% (1000/1776 records)\n",
      "  Progress: 84.5% (1500/1776 records)\n",
      "  Progress: 84.5% (1500/1776 records)\n",
      "\n",
      "Weather extraction completed!\n",
      "Successful extractions: 1776\n",
      "Failed extractions: 0\n",
      "Success rate: 100.0%\n",
      "\n",
      "Weather extraction completed!\n",
      "Successful extractions: 1776\n",
      "Failed extractions: 0\n",
      "Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Apply weather extraction to the merged dataset\n",
    "print(\"Extracting extreme weather data for each typhoon impact...\")\n",
    "\n",
    "# Initialize weather columns in the final dataset\n",
    "final_merged_data['Max_24hr_Rainfall_mm'] = np.nan\n",
    "final_merged_data['Total_Storm_Rainfall_mm'] = np.nan\n",
    "final_merged_data['Min_Pressure_hPa'] = np.nan\n",
    "final_merged_data['Weather_Records_Found'] = 0\n",
    "final_merged_data['Weather_Days_Covered'] = 0\n",
    "final_merged_data['Weather_Station_Mapped'] = 0\n",
    "\n",
    "# Process in batches for progress tracking\n",
    "batch_size = 100\n",
    "total_records = len(final_merged_data)\n",
    "successful_extractions = 0\n",
    "failed_extractions = 0\n",
    "\n",
    "print(f\"Processing {total_records} records in batches of {batch_size}...\")\n",
    "\n",
    "for i in range(0, total_records, batch_size):\n",
    "    batch_end = min(i + batch_size, total_records)\n",
    "    \n",
    "    for idx in range(i, batch_end):\n",
    "        row = final_merged_data.iloc[idx]\n",
    "        \n",
    "        # Check if we have the required data\n",
    "        impact_station = row['Nearest_Station']\n",
    "        par_start = row['PAR_START']\n",
    "        par_end = row['PAR_END']\n",
    "        \n",
    "        # Skip if missing required data\n",
    "        if pd.isna(impact_station) or pd.isna(par_start) or pd.isna(par_end):\n",
    "            failed_extractions += 1\n",
    "            continue\n",
    "        \n",
    "        # Check if station can be mapped\n",
    "        if impact_station not in station_mapping:\n",
    "            failed_extractions += 1\n",
    "            continue\n",
    "        \n",
    "        weather_station = station_mapping[impact_station]\n",
    "        final_merged_data.at[idx, 'Weather_Station_Mapped'] = 1\n",
    "        \n",
    "        # Extract weather data\n",
    "        weather_result = extract_extreme_weather_for_typhoon(\n",
    "            weather_data_clean, weather_station, par_start, par_end, stations_info\n",
    "        )\n",
    "        \n",
    "        # Update the dataset with extracted values\n",
    "        final_merged_data.at[idx, 'Max_24hr_Rainfall_mm'] = weather_result['Max_24hr_Rainfall_mm']\n",
    "        final_merged_data.at[idx, 'Total_Storm_Rainfall_mm'] = weather_result['Total_Storm_Rainfall_mm']\n",
    "        final_merged_data.at[idx, 'Min_Pressure_hPa'] = weather_result['Min_Pressure_hPa']\n",
    "        final_merged_data.at[idx, 'Weather_Records_Found'] = weather_result['records_found']\n",
    "        final_merged_data.at[idx, 'Weather_Days_Covered'] = weather_result['days_covered']\n",
    "        \n",
    "        if weather_result['records_found'] > 0:\n",
    "            successful_extractions += 1\n",
    "        else:\n",
    "            failed_extractions += 1\n",
    "    \n",
    "    # Progress update\n",
    "    if (i // batch_size + 1) % 5 == 0:\n",
    "        progress = (batch_end / total_records) * 100\n",
    "        print(f\"  Progress: {progress:.1f}% ({batch_end}/{total_records} records)\")\n",
    "\n",
    "print(f\"\\nWeather extraction completed!\")\n",
    "print(f\"Successful extractions: {successful_extractions}\")\n",
    "print(f\"Failed extractions: {failed_extractions}\")\n",
    "print(f\"Success rate: {(successful_extractions / total_records) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba36237d",
   "metadata": {},
   "source": [
    "## Analyze Extracted Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d8953450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXTREME WEATHER DATA ANALYSIS ===\n",
      "\n",
      "Weather data summary:\n",
      "       Max_24hr_Rainfall_mm  Total_Storm_Rainfall_mm  Min_Pressure_hPa\n",
      "count           1776.000000              1776.000000       1775.000000\n",
      "mean             103.854302               168.839127        995.850592\n",
      "std               71.202587               111.019046          9.929892\n",
      "min                0.000000                 0.000000        924.900000\n",
      "25%               50.400000                78.902500        992.200000\n",
      "50%               98.500000               151.200000        998.100000\n",
      "75%              136.200000               237.200000       1001.800000\n",
      "max              510.000000               770.500000       1008.600000\n",
      "\n",
      "=== COVERAGE STATISTICS ===\n",
      "Total impact records: 1,776\n",
      "Records with mapped weather stations: 1,776 (100.0%)\n",
      "Max_24hr_Rainfall_mm: 1,776 records (100.0%)\n",
      "Total_Storm_Rainfall_mm: 1,776 records (100.0%)\n",
      "Min_Pressure_hPa: 1,775 records (99.9%)\n",
      "\n",
      "=== EXTREME VALUES RECORDED ===\n",
      "Highest 24hr rainfall: 510.0 mm\n",
      "Highest total storm rainfall: 770.5 mm\n",
      "Lowest pressure recorded: 924.9 hPa\n",
      "\n",
      "=== RECORDS WITH COMPLETE WEATHER DATA ===\n",
      "Records with all weather metrics: 1,775 (99.9%)\n",
      "\n",
      "Sample records with complete weather data:\n",
      "  Typhoon Name  Year Province Nearest_Station  PAR_START    PAR_END  \\\n",
      "0        BETTY  2023  BATANES           BASCO 2023-05-27 2023-06-01   \n",
      "1        BETTY  2023  BATANES         ITBAYAT 2023-05-27 2023-06-01   \n",
      "2        BETTY  2023  BATANES           BASCO 2023-05-27 2023-06-01   \n",
      "3        BETTY  2023  BATANES           BASCO 2023-05-27 2023-06-01   \n",
      "4        BETTY  2023  BATANES           BASCO 2023-05-27 2023-06-01   \n",
      "\n",
      "   Max_24hr_Rainfall_mm  Total_Storm_Rainfall_mm  Min_Pressure_hPa  \n",
      "0                  25.6                    39.00             977.1  \n",
      "1                  20.3                    32.71            1000.5  \n",
      "2                  25.6                    39.00             977.1  \n",
      "3                  25.6                    39.00             977.1  \n",
      "4                  25.6                    39.00             977.1  \n"
     ]
    }
   ],
   "source": [
    "# Analyze the extracted weather data\n",
    "print(\"=== EXTREME WEATHER DATA ANALYSIS ===\")\n",
    "\n",
    "# Basic statistics\n",
    "weather_cols = ['Max_24hr_Rainfall_mm', 'Total_Storm_Rainfall_mm', 'Min_Pressure_hPa']\n",
    "print(\"\\nWeather data summary:\")\n",
    "print(final_merged_data[weather_cols].describe())\n",
    "\n",
    "# Coverage statistics\n",
    "total_records = len(final_merged_data)\n",
    "mapped_stations = final_merged_data['Weather_Station_Mapped'].sum()\n",
    "records_with_data = final_merged_data['Weather_Records_Found'].sum()\n",
    "\n",
    "print(f\"\\n=== COVERAGE STATISTICS ===\")\n",
    "print(f\"Total impact records: {total_records:,}\")\n",
    "print(f\"Records with mapped weather stations: {mapped_stations:,} ({mapped_stations/total_records*100:.1f}%)\")\n",
    "\n",
    "# Check data availability for each weather metric\n",
    "for col in weather_cols:\n",
    "    non_null = final_merged_data[col].notna().sum()\n",
    "    print(f\"{col}: {non_null:,} records ({non_null/total_records*100:.1f}%)\")\n",
    "\n",
    "# Show some extreme values\n",
    "print(f\"\\n=== EXTREME VALUES RECORDED ===\")\n",
    "\n",
    "# Highest rainfall values\n",
    "max_24hr = final_merged_data['Max_24hr_Rainfall_mm'].max()\n",
    "max_total = final_merged_data['Total_Storm_Rainfall_mm'].max()\n",
    "min_pressure = final_merged_data['Min_Pressure_hPa'].min()\n",
    "\n",
    "if not pd.isna(max_24hr):\n",
    "    print(f\"Highest 24hr rainfall: {max_24hr:.1f} mm\")\n",
    "if not pd.isna(max_total):\n",
    "    print(f\"Highest total storm rainfall: {max_total:.1f} mm\")\n",
    "if not pd.isna(min_pressure):\n",
    "    print(f\"Lowest pressure recorded: {min_pressure:.1f} hPa\")\n",
    "\n",
    "# Show sample of records with complete weather data\n",
    "complete_weather = final_merged_data[\n",
    "    final_merged_data['Max_24hr_Rainfall_mm'].notna() &\n",
    "    final_merged_data['Total_Storm_Rainfall_mm'].notna() &\n",
    "    final_merged_data['Min_Pressure_hPa'].notna()\n",
    "]\n",
    "\n",
    "print(f\"\\n=== RECORDS WITH COMPLETE WEATHER DATA ===\")\n",
    "print(f\"Records with all weather metrics: {len(complete_weather):,} ({len(complete_weather)/total_records*100:.1f}%)\")\n",
    "\n",
    "if len(complete_weather) > 0:\n",
    "    print(\"\\nSample records with complete weather data:\")\n",
    "    sample_cols = ['Typhoon Name', 'Year', 'Province', 'Nearest_Station', 'PAR_START', 'PAR_END',\n",
    "                   'Max_24hr_Rainfall_mm', 'Total_Storm_Rainfall_mm', 'Min_Pressure_hPa']\n",
    "    available_cols = [col for col in sample_cols if col in complete_weather.columns]\n",
    "    print(complete_weather[available_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e32562",
   "metadata": {},
   "source": [
    "## Export Final Dataset with Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "5ca285c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing final dataset for export...\n",
      "Final dataset shape: (1776, 30)\n",
      "Final columns: ['Typhoon Name', 'Year', 'Region', 'Province', 'City/Municipality', 'Families', 'Person', 'Brgy', 'Dead', 'Injured/Ill', 'Missing', 'Totally', 'Partially', 'Total', 'Quantity', 'Cost', 'Nearest_Station', 'Station_Province', 'Distance_km', 'PAR_START', 'PAR_END', 'Duration_in_PAR_Hours', 'Max_Sustained_Wind_kph', 'Typhoon_Type', 'Max_24hr_Rainfall_mm', 'Total_Storm_Rainfall_mm', 'Min_Pressure_hPa', 'Weather_Station_Mapped', 'Weather_Records_Found', 'Weather_Days_Covered']\n",
      "\n",
      "Dataset successfully exported to: ../../data/typhoon_impact_with_extreme_weather.csv\n",
      "\n",
      "Total records exported: 1,776\n",
      "Records with weather data: 1,776\n"
     ]
    }
   ],
   "source": [
    "# Prepare final dataset for export\n",
    "print(\"Preparing final dataset for export...\")\n",
    "\n",
    "# Reorder columns to group related data together\n",
    "# Basic typhoon info\n",
    "basic_cols = ['Typhoon Name', 'Year', 'Region', 'Province', 'City/Municipality']\n",
    "# Impact data\n",
    "impact_cols = ['Families', 'Person', 'Brgy', 'Dead', 'Injured/Ill', 'Missing', \n",
    "               'Totally', 'Partially', 'Total', 'Quantity', 'Cost', 'Type', 'Category']\n",
    "# Station info\n",
    "station_cols = ['Nearest_Station', 'Station_Province', 'Distance_km']\n",
    "# Typhoon characteristics\n",
    "typhoon_cols = ['PAR_START', 'PAR_END', 'Duration_in_PAR_Hours', 'Max_Sustained_Wind_kph', 'Typhoon_Type']\n",
    "# Weather data\n",
    "weather_cols = ['Max_24hr_Rainfall_mm', 'Total_Storm_Rainfall_mm', 'Min_Pressure_hPa']\n",
    "# Metadata\n",
    "meta_cols = ['Weather_Station_Mapped', 'Weather_Records_Found', 'Weather_Days_Covered']\n",
    "\n",
    "# Get only columns that exist in the dataset\n",
    "all_desired_cols = basic_cols + impact_cols + station_cols + typhoon_cols + weather_cols + meta_cols\n",
    "final_columns = [col for col in all_desired_cols if col in final_merged_data.columns]\n",
    "\n",
    "# Add any remaining columns\n",
    "remaining_cols = [col for col in final_merged_data.columns if col not in final_columns]\n",
    "final_columns.extend(remaining_cols)\n",
    "\n",
    "# Reorder the dataset\n",
    "final_export_data = final_merged_data[final_columns].copy()\n",
    "\n",
    "print(f\"Final dataset shape: {final_export_data.shape}\")\n",
    "print(f\"Final columns: {final_export_data.columns.tolist()}\")\n",
    "\n",
    "# Export to CSV\n",
    "output_filename = 'typhoon_impact_with_extreme_weather.csv'\n",
    "try:\n",
    "    final_export_data.to_csv(f'../../data/{output_filename}', index=False)\n",
    "    print(f\"\\nDataset successfully exported to: ../../data/{output_filename}\")\n",
    "except:\n",
    "    # Fallback to current directory\n",
    "    final_export_data.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nDataset exported to current directory: {output_filename}\")\n",
    "\n",
    "print(f\"\\nTotal records exported: {len(final_export_data):,}\")\n",
    "print(f\"Records with weather data: {final_export_data['Weather_Station_Mapped'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "46f3d795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                    FINAL PROCESSING SUMMARY\n",
      "================================================================================\n",
      "📊 DATASET OVERVIEW:\n",
      "   Total typhoon impact records: 1,776\n",
      "   Unique typhoons: 25\n",
      "   Year range: 2020-2023\n",
      "   Provinces affected: 24\n",
      "\n",
      "🌦️  EXTREME WEATHER DATA:\n",
      "   Records with weather stations mapped: 1,776 (100.0%)\n",
      "   Maximum 24-hour rainfall: 1,776 records (100.0%)\n",
      "   Total storm rainfall: 1,776 records (100.0%)\n",
      "   Minimum pressure: 1,775 records (99.9%)\n",
      "\n",
      "📈 EXTREME VALUES CAPTURED:\n",
      "   Highest 24hr rainfall: 510.0 mm\n",
      "   Highest total rainfall: 770.5 mm\n",
      "   Lowest pressure: 924.9 hPa\n",
      "\n",
      "💾 OUTPUT:\n",
      "   File: typhoon_impact_with_extreme_weather.csv\n",
      "   Size: 1.0 MB\n",
      "================================================================================\n",
      "✅ PROCESSING COMPLETED SUCCESSFULLY!\n",
      "   Dataset now includes extreme weather values during typhoon periods.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"=\"*80)\n",
    "print(\"                    FINAL PROCESSING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"📊 DATASET OVERVIEW:\")\n",
    "print(f\"   Total typhoon impact records: {len(final_export_data):,}\")\n",
    "print(f\"   Unique typhoons: {final_export_data['Typhoon Name'].nunique()}\")\n",
    "print(f\"   Year range: {final_export_data['Year'].min()}-{final_export_data['Year'].max()}\")\n",
    "print(f\"   Provinces affected: {final_export_data['Province'].nunique()}\")\n",
    "\n",
    "weather_coverage = final_export_data['Weather_Station_Mapped'].sum()\n",
    "coverage_pct = (weather_coverage / len(final_export_data)) * 100\n",
    "\n",
    "print(f\"\\n🌦️  EXTREME WEATHER DATA:\")\n",
    "print(f\"   Records with weather stations mapped: {weather_coverage:,} ({coverage_pct:.1f}%)\")\n",
    "\n",
    "for col, desc in [\n",
    "    ('Max_24hr_Rainfall_mm', 'Maximum 24-hour rainfall'),\n",
    "    ('Total_Storm_Rainfall_mm', 'Total storm rainfall'),\n",
    "    ('Min_Pressure_hPa', 'Minimum pressure')\n",
    "]:\n",
    "    non_null = final_export_data[col].notna().sum()\n",
    "    pct = (non_null / len(final_export_data)) * 100\n",
    "    print(f\"   {desc}: {non_null:,} records ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📈 EXTREME VALUES CAPTURED:\")\n",
    "if not final_export_data['Max_24hr_Rainfall_mm'].isna().all():\n",
    "    max_rain = final_export_data['Max_24hr_Rainfall_mm'].max()\n",
    "    print(f\"   Highest 24hr rainfall: {max_rain:.1f} mm\")\n",
    "\n",
    "if not final_export_data['Total_Storm_Rainfall_mm'].isna().all():\n",
    "    max_total = final_export_data['Total_Storm_Rainfall_mm'].max()\n",
    "    print(f\"   Highest total rainfall: {max_total:.1f} mm\")\n",
    "\n",
    "if not final_export_data['Min_Pressure_hPa'].isna().all():\n",
    "    min_press = final_export_data['Min_Pressure_hPa'].min()\n",
    "    print(f\"   Lowest pressure: {min_press:.1f} hPa\")\n",
    "\n",
    "print(f\"\\n💾 OUTPUT:\")\n",
    "print(f\"   File: {output_filename}\")\n",
    "print(f\"   Size: {final_export_data.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✅ PROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"   Dataset now includes extreme weather values during typhoon periods.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "59eebc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Typhoon Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Region",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City/Municipality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Families",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Person",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brgy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dead",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Injured/Ill",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Missing",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Totally",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Partially",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Nearest_Station",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Station_Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Distance_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PAR_START",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "PAR_END",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Duration_in_PAR_Hours",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Max_Sustained_Wind_kph",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Typhoon_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Max_24hr_Rainfall_mm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total_Storm_Rainfall_mm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Min_Pressure_hPa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weather_Station_Mapped",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Weather_Records_Found",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Weather_Days_Covered",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "df3d08df-2499-418f-a91e-5e7d7b48faf2",
       "rows": [
        [
         "0",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "BASCO",
         "3608",
         "11120",
         "6",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "3608",
         "2646179.36",
         "BASCO",
         "BATANES",
         "2.497503561",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "133.0",
         "195",
         "STY",
         "25.6",
         "39.0",
         "977.1",
         "1",
         "6",
         "6"
        ],
        [
         "1",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "ITBAYAT",
         "968",
         "3028",
         "5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "966",
         "494592.0",
         "ITBAYAT",
         "BATANES",
         "3.204942957",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "133.0",
         "195",
         "STY",
         "20.3",
         "32.71",
         "1000.5",
         "1",
         "6",
         "6"
        ],
        [
         "2",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "IVANA",
         "444",
         "1532",
         "4",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "444",
         "227328.0",
         "BASCO",
         "BATANES",
         "9.470553732",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "133.0",
         "195",
         "STY",
         "25.6",
         "39.0",
         "977.1",
         "1",
         "6",
         "6"
        ],
        [
         "3",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "MAHATAO",
         "575",
         "1792",
         "4",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "575",
         "291082.96",
         "BASCO",
         "BATANES",
         "4.890815627",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "133.0",
         "195",
         "STY",
         "25.6",
         "39.0",
         "977.1",
         "1",
         "6",
         "6"
        ],
        [
         "4",
         "BETTY",
         "2023",
         "2",
         "BATANES",
         "SABTANG",
         "575",
         "1955",
         "6",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "575",
         "296521.75",
         "BASCO",
         "BATANES",
         "19.89123103",
         "2023-05-27 00:00:00",
         "2023-06-01 00:00:00",
         "133.0",
         "195",
         "STY",
         "25.6",
         "39.0",
         "977.1",
         "1",
         "6",
         "6"
        ]
       ],
       "shape": {
        "columns": 30,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typhoon Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Region</th>\n",
       "      <th>Province</th>\n",
       "      <th>City/Municipality</th>\n",
       "      <th>Families</th>\n",
       "      <th>Person</th>\n",
       "      <th>Brgy</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Injured/Ill</th>\n",
       "      <th>...</th>\n",
       "      <th>PAR_END</th>\n",
       "      <th>Duration_in_PAR_Hours</th>\n",
       "      <th>Max_Sustained_Wind_kph</th>\n",
       "      <th>Typhoon_Type</th>\n",
       "      <th>Max_24hr_Rainfall_mm</th>\n",
       "      <th>Total_Storm_Rainfall_mm</th>\n",
       "      <th>Min_Pressure_hPa</th>\n",
       "      <th>Weather_Station_Mapped</th>\n",
       "      <th>Weather_Records_Found</th>\n",
       "      <th>Weather_Days_Covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>BASCO</td>\n",
       "      <td>3608</td>\n",
       "      <td>11120</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>133.0</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "      <td>25.6</td>\n",
       "      <td>39.00</td>\n",
       "      <td>977.1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>ITBAYAT</td>\n",
       "      <td>968</td>\n",
       "      <td>3028</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>133.0</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "      <td>20.3</td>\n",
       "      <td>32.71</td>\n",
       "      <td>1000.5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>IVANA</td>\n",
       "      <td>444</td>\n",
       "      <td>1532</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>133.0</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "      <td>25.6</td>\n",
       "      <td>39.00</td>\n",
       "      <td>977.1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>MAHATAO</td>\n",
       "      <td>575</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>133.0</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "      <td>25.6</td>\n",
       "      <td>39.00</td>\n",
       "      <td>977.1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BETTY</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BATANES</td>\n",
       "      <td>SABTANG</td>\n",
       "      <td>575</td>\n",
       "      <td>1955</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>133.0</td>\n",
       "      <td>195</td>\n",
       "      <td>STY</td>\n",
       "      <td>25.6</td>\n",
       "      <td>39.00</td>\n",
       "      <td>977.1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Typhoon Name  Year  Region Province City/Municipality  Families  Person  \\\n",
       "0        BETTY  2023       2  BATANES             BASCO      3608   11120   \n",
       "1        BETTY  2023       2  BATANES           ITBAYAT       968    3028   \n",
       "2        BETTY  2023       2  BATANES             IVANA       444    1532   \n",
       "3        BETTY  2023       2  BATANES           MAHATAO       575    1792   \n",
       "4        BETTY  2023       2  BATANES           SABTANG       575    1955   \n",
       "\n",
       "   Brgy  Dead  Injured/Ill  ...    PAR_END  Duration_in_PAR_Hours  \\\n",
       "0     6     0            0  ... 2023-06-01                  133.0   \n",
       "1     5     0            0  ... 2023-06-01                  133.0   \n",
       "2     4     0            0  ... 2023-06-01                  133.0   \n",
       "3     4     0            0  ... 2023-06-01                  133.0   \n",
       "4     6     0            0  ... 2023-06-01                  133.0   \n",
       "\n",
       "   Max_Sustained_Wind_kph  Typhoon_Type  Max_24hr_Rainfall_mm  \\\n",
       "0                     195           STY                  25.6   \n",
       "1                     195           STY                  20.3   \n",
       "2                     195           STY                  25.6   \n",
       "3                     195           STY                  25.6   \n",
       "4                     195           STY                  25.6   \n",
       "\n",
       "   Total_Storm_Rainfall_mm Min_Pressure_hPa Weather_Station_Mapped  \\\n",
       "0                    39.00            977.1                      1   \n",
       "1                    32.71           1000.5                      1   \n",
       "2                    39.00            977.1                      1   \n",
       "3                    39.00            977.1                      1   \n",
       "4                    39.00            977.1                      1   \n",
       "\n",
       "   Weather_Records_Found Weather_Days_Covered  \n",
       "0                      6                    6  \n",
       "1                      6                    6  \n",
       "2                      6                    6  \n",
       "3                      6                    6  \n",
       "4                      6                    6  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_export_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "a67262b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                    STATION ANALYSIS REPORT\n",
      "================================================================================\n",
      "\n",
      "📍 IMPACT STATIONS (22 total):\n",
      "--------------------------------------------------\n",
      "   1. 'APARRI' → 'Aparri'\n",
      "   2. 'BALER' → 'Baler (Radar)'\n",
      "   3. 'BASCO' → 'Basco (Radar)'\n",
      "   4. 'BORONGAN' → 'Borongan'\n",
      "   5. 'CABANATUAN' → 'CLSU Muñoz'\n",
      "   6. 'CALAYAN' → 'Calayan'\n",
      "   7. 'CASIGURAN' → 'Casiguran'\n",
      "   8. 'CATARMAN' → 'Catarman'\n",
      "   9. 'CATBALOGAN' → 'Catbalogan'\n",
      "  10. 'CLARK AIRPORT' → 'Clark Airport (DMIA)'\n",
      "  11. 'DAET' → 'Daet'\n",
      "  12. 'GUIUAN' → 'Guiuan'\n",
      "  13. 'IBA' → 'Iba'\n",
      "  14. 'ITBAYAT' → 'Itbayat'\n",
      "  15. 'JUBAN' → 'Juban'\n",
      "  16. 'LEGAZPI CITY' → 'Legazpi City'\n",
      "  17. 'MAASIN' → 'Maasin'\n",
      "  18. 'MASBATE' → 'Masbate City'\n",
      "  19. 'SUBIC BAY' → 'Cubi Pt.'\n",
      "  20. 'TACLOBAN' → 'Tacloban City'\n",
      "  21. 'TUGUEGARAO' → 'Tuguegarao City'\n",
      "  22. 'VIRAC' → 'Virac (Synop)'\n",
      "\n",
      "🌦️  WEATHER STATIONS (22 total):\n",
      "--------------------------------------------------\n",
      "   1. 'Aparri' (Rainfall, Pressure, Wind)\n",
      "   2. 'Baler (Radar)' (Rainfall, Pressure, Wind)\n",
      "   3. 'Basco (Radar)' (Rainfall, Pressure, Wind)\n",
      "   4. 'Borongan' (Rainfall, Pressure, Wind)\n",
      "   5. 'CLSU Muñoz' (Rainfall, Pressure, Wind)\n",
      "   6. 'Calayan' (Rainfall, Pressure, Wind)\n",
      "   7. 'Casiguran' (Rainfall, Pressure, Wind)\n",
      "   8. 'Catarman' (Rainfall, Pressure, Wind)\n",
      "   9. 'Catbalogan' (Rainfall, Pressure, Wind)\n",
      "  10. 'Clark Airport (DMIA)' (Rainfall, Pressure, Wind)\n",
      "  11. 'Cubi Pt.' (Rainfall, Pressure, Wind)\n",
      "  12. 'Daet' (Rainfall, Pressure, Wind)\n",
      "  13. 'Guiuan' (Rainfall, Pressure, Wind)\n",
      "  14. 'Iba' (Rainfall, Pressure, Wind)\n",
      "  15. 'Itbayat' (Rainfall, Pressure, Wind)\n",
      "  16. 'Juban' (Rainfall, Pressure, Wind)\n",
      "  17. 'Legazpi City' (Rainfall, Pressure, Wind)\n",
      "  18. 'Maasin' (Rainfall, Pressure, Wind)\n",
      "  19. 'Masbate City' (Rainfall, Pressure, Wind)\n",
      "  20. 'Tacloban City' (Rainfall, Pressure, Wind)\n",
      "  21. 'Tuguegarao City' (Rainfall, Pressure, Wind)\n",
      "  22. 'Virac (Synop)' (Rainfall, Pressure, Wind)\n",
      "\n",
      "🔗 MAPPING SUMMARY:\n",
      "--------------------------------------------------\n",
      "Total Impact Stations: 22\n",
      "Total Weather Stations: 22\n",
      "Successfully Mapped: 22\n",
      "Unmapped: 0\n",
      "Mapping Success Rate: 100.0%\n",
      "\n",
      "✅ SUCCESSFUL MAPPINGS (22):\n",
      "--------------------------------------------------\n",
      "   1. 'APARRI' → 'Aparri'\n",
      "   2. 'BALER' → 'Baler (Radar)'\n",
      "   3. 'BASCO' → 'Basco (Radar)'\n",
      "   4. 'BORONGAN' → 'Borongan'\n",
      "   5. 'CABANATUAN' → 'CLSU Muñoz'\n",
      "   6. 'CALAYAN' → 'Calayan'\n",
      "   7. 'CASIGURAN' → 'Casiguran'\n",
      "   8. 'CATARMAN' → 'Catarman'\n",
      "   9. 'CATBALOGAN' → 'Catbalogan'\n",
      "  10. 'CLARK AIRPORT' → 'Clark Airport (DMIA)'\n",
      "  11. 'DAET' → 'Daet'\n",
      "  12. 'GUIUAN' → 'Guiuan'\n",
      "  13. 'IBA' → 'Iba'\n",
      "  14. 'ITBAYAT' → 'Itbayat'\n",
      "  15. 'JUBAN' → 'Juban'\n",
      "  16. 'LEGAZPI CITY' → 'Legazpi City'\n",
      "  17. 'MAASIN' → 'Maasin'\n",
      "  18. 'MASBATE' → 'Masbate City'\n",
      "  19. 'SUBIC BAY' → 'Cubi Pt.'\n",
      "  20. 'TACLOBAN' → 'Tacloban City'\n",
      "  21. 'TUGUEGARAO' → 'Tuguegarao City'\n",
      "  22. 'VIRAC' → 'Virac (Synop)'\n",
      "\n",
      "📊 WEATHER DATA COVERAGE:\n",
      "--------------------------------------------------\n",
      "Total typhoon impact records: 1,776\n",
      "Records with mapped stations: 1,776 (100.0%)\n",
      "Records with rainfall data: 1,776 (100.0%)\n",
      "Records with pressure data: 1,775 (99.9%)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "📍 IMPACT STATIONS (22 total):\n",
      "--------------------------------------------------\n",
      "   1. 'APARRI' → 'Aparri'\n",
      "   2. 'BALER' → 'Baler (Radar)'\n",
      "   3. 'BASCO' → 'Basco (Radar)'\n",
      "   4. 'BORONGAN' → 'Borongan'\n",
      "   5. 'CABANATUAN' → 'CLSU Muñoz'\n",
      "   6. 'CALAYAN' → 'Calayan'\n",
      "   7. 'CASIGURAN' → 'Casiguran'\n",
      "   8. 'CATARMAN' → 'Catarman'\n",
      "   9. 'CATBALOGAN' → 'Catbalogan'\n",
      "  10. 'CLARK AIRPORT' → 'Clark Airport (DMIA)'\n",
      "  11. 'DAET' → 'Daet'\n",
      "  12. 'GUIUAN' → 'Guiuan'\n",
      "  13. 'IBA' → 'Iba'\n",
      "  14. 'ITBAYAT' → 'Itbayat'\n",
      "  15. 'JUBAN' → 'Juban'\n",
      "  16. 'LEGAZPI CITY' → 'Legazpi City'\n",
      "  17. 'MAASIN' → 'Maasin'\n",
      "  18. 'MASBATE' → 'Masbate City'\n",
      "  19. 'SUBIC BAY' → 'Cubi Pt.'\n",
      "  20. 'TACLOBAN' → 'Tacloban City'\n",
      "  21. 'TUGUEGARAO' → 'Tuguegarao City'\n",
      "  22. 'VIRAC' → 'Virac (Synop)'\n",
      "\n",
      "🌦️  WEATHER STATIONS (22 total):\n",
      "--------------------------------------------------\n",
      "   1. 'Aparri' (Rainfall, Pressure, Wind)\n",
      "   2. 'Baler (Radar)' (Rainfall, Pressure, Wind)\n",
      "   3. 'Basco (Radar)' (Rainfall, Pressure, Wind)\n",
      "   4. 'Borongan' (Rainfall, Pressure, Wind)\n",
      "   5. 'CLSU Muñoz' (Rainfall, Pressure, Wind)\n",
      "   6. 'Calayan' (Rainfall, Pressure, Wind)\n",
      "   7. 'Casiguran' (Rainfall, Pressure, Wind)\n",
      "   8. 'Catarman' (Rainfall, Pressure, Wind)\n",
      "   9. 'Catbalogan' (Rainfall, Pressure, Wind)\n",
      "  10. 'Clark Airport (DMIA)' (Rainfall, Pressure, Wind)\n",
      "  11. 'Cubi Pt.' (Rainfall, Pressure, Wind)\n",
      "  12. 'Daet' (Rainfall, Pressure, Wind)\n",
      "  13. 'Guiuan' (Rainfall, Pressure, Wind)\n",
      "  14. 'Iba' (Rainfall, Pressure, Wind)\n",
      "  15. 'Itbayat' (Rainfall, Pressure, Wind)\n",
      "  16. 'Juban' (Rainfall, Pressure, Wind)\n",
      "  17. 'Legazpi City' (Rainfall, Pressure, Wind)\n",
      "  18. 'Maasin' (Rainfall, Pressure, Wind)\n",
      "  19. 'Masbate City' (Rainfall, Pressure, Wind)\n",
      "  20. 'Tacloban City' (Rainfall, Pressure, Wind)\n",
      "  21. 'Tuguegarao City' (Rainfall, Pressure, Wind)\n",
      "  22. 'Virac (Synop)' (Rainfall, Pressure, Wind)\n",
      "\n",
      "🔗 MAPPING SUMMARY:\n",
      "--------------------------------------------------\n",
      "Total Impact Stations: 22\n",
      "Total Weather Stations: 22\n",
      "Successfully Mapped: 22\n",
      "Unmapped: 0\n",
      "Mapping Success Rate: 100.0%\n",
      "\n",
      "✅ SUCCESSFUL MAPPINGS (22):\n",
      "--------------------------------------------------\n",
      "   1. 'APARRI' → 'Aparri'\n",
      "   2. 'BALER' → 'Baler (Radar)'\n",
      "   3. 'BASCO' → 'Basco (Radar)'\n",
      "   4. 'BORONGAN' → 'Borongan'\n",
      "   5. 'CABANATUAN' → 'CLSU Muñoz'\n",
      "   6. 'CALAYAN' → 'Calayan'\n",
      "   7. 'CASIGURAN' → 'Casiguran'\n",
      "   8. 'CATARMAN' → 'Catarman'\n",
      "   9. 'CATBALOGAN' → 'Catbalogan'\n",
      "  10. 'CLARK AIRPORT' → 'Clark Airport (DMIA)'\n",
      "  11. 'DAET' → 'Daet'\n",
      "  12. 'GUIUAN' → 'Guiuan'\n",
      "  13. 'IBA' → 'Iba'\n",
      "  14. 'ITBAYAT' → 'Itbayat'\n",
      "  15. 'JUBAN' → 'Juban'\n",
      "  16. 'LEGAZPI CITY' → 'Legazpi City'\n",
      "  17. 'MAASIN' → 'Maasin'\n",
      "  18. 'MASBATE' → 'Masbate City'\n",
      "  19. 'SUBIC BAY' → 'Cubi Pt.'\n",
      "  20. 'TACLOBAN' → 'Tacloban City'\n",
      "  21. 'TUGUEGARAO' → 'Tuguegarao City'\n",
      "  22. 'VIRAC' → 'Virac (Synop)'\n",
      "\n",
      "📊 WEATHER DATA COVERAGE:\n",
      "--------------------------------------------------\n",
      "Total typhoon impact records: 1,776\n",
      "Records with mapped stations: 1,776 (100.0%)\n",
      "Records with rainfall data: 1,776 (100.0%)\n",
      "Records with pressure data: 1,775 (99.9%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print comprehensive station lists and mapping analysis\n",
    "print(\"=\" * 80)\n",
    "print(\"                    STATION ANALYSIS REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get the station lists\n",
    "impact_stations = final_merged_data['Nearest_Station'].dropna().unique()\n",
    "weather_stations = list(stations_info.keys())\n",
    "\n",
    "print(f\"\\n📍 IMPACT STATIONS ({len(impact_stations)} total):\")\n",
    "print(\"-\" * 50)\n",
    "for i, station in enumerate(sorted(impact_stations), 1):\n",
    "    mapped_status = \"✓ MAPPED\" if station in station_mapping else \"✗ UNMAPPED\"\n",
    "    if station in station_mapping:\n",
    "        weather_match = station_mapping[station]\n",
    "        print(f\"  {i:2d}. '{station}' → '{weather_match}'\")\n",
    "    else:\n",
    "        print(f\"  {i:2d}. '{station}' → {mapped_status}\")\n",
    "\n",
    "print(f\"\\n🌦️  WEATHER STATIONS ({len(weather_stations)} total):\")\n",
    "print(\"-\" * 50)\n",
    "for i, station in enumerate(sorted(weather_stations), 1):\n",
    "    # Check what metrics this station has\n",
    "    metrics = stations_info[station]\n",
    "    available_metrics = []\n",
    "    if metrics['rainfall']: available_metrics.append(\"Rainfall\")\n",
    "    if metrics['pressure']: available_metrics.append(\"Pressure\") \n",
    "    if metrics['wind_speed']: available_metrics.append(\"Wind\")\n",
    "    \n",
    "    metrics_str = \", \".join(available_metrics) if available_metrics else \"No metrics\"\n",
    "    print(f\"  {i:2d}. '{station}' ({metrics_str})\")\n",
    "\n",
    "print(f\"\\n🔗 MAPPING SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total Impact Stations: {len(impact_stations)}\")\n",
    "print(f\"Total Weather Stations: {len(weather_stations)}\")\n",
    "print(f\"Successfully Mapped: {len(station_mapping)}\")\n",
    "print(f\"Unmapped: {len(impact_stations) - len(station_mapping)}\")\n",
    "print(f\"Mapping Success Rate: {(len(station_mapping) / len(impact_stations)) * 100:.1f}%\")\n",
    "\n",
    "# Show unmapped stations\n",
    "unmapped = [s for s in impact_stations if s not in station_mapping]\n",
    "if unmapped:\n",
    "    print(f\"\\n❌ UNMAPPED IMPACT STATIONS ({len(unmapped)}):\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, station in enumerate(unmapped, 1):\n",
    "        print(f\"  {i:2d}. '{station}'\")\n",
    "\n",
    "# Show successful mappings grouped by type\n",
    "print(f\"\\n✅ SUCCESSFUL MAPPINGS ({len(station_mapping)}):\")\n",
    "print(\"-\" * 50)\n",
    "for i, (impact, weather) in enumerate(sorted(station_mapping.items()), 1):\n",
    "    print(f\"  {i:2d}. '{impact}' → '{weather}'\")\n",
    "\n",
    "# Check weather data coverage for mapped stations\n",
    "print(f\"\\n📊 WEATHER DATA COVERAGE:\")\n",
    "print(\"-\" * 50)\n",
    "total_records = len(final_merged_data)\n",
    "mapped_records = final_merged_data['Weather_Station_Mapped'].sum()\n",
    "rainfall_records = final_merged_data['Max_24hr_Rainfall_mm'].notna().sum()\n",
    "pressure_records = final_merged_data['Min_Pressure_hPa'].notna().sum()\n",
    "\n",
    "print(f\"Total typhoon impact records: {total_records:,}\")\n",
    "print(f\"Records with mapped stations: {mapped_records:,} ({mapped_records/total_records*100:.1f}%)\")\n",
    "print(f\"Records with rainfall data: {rainfall_records:,} ({rainfall_records/total_records*100:.1f}%)\")\n",
    "print(f\"Records with pressure data: {pressure_records:,} ({pressure_records/total_records*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb3bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
